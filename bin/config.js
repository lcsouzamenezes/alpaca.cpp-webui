const config = {
  // The ./chat can be downloaded from alpaca.cpp
  EXECUTABLE_FILE: './chat',
  MODEL_FILE: './ggml-alpaca-7b-q4.bin',

  // Alternatively, the gpt4all-lora-quantized can be downloaded from nomic-ai/gpt4all
  // BIN_FILE: './gpt4all-lora-quantized-linux-x86',
  // MODEL_FILE :'./gpt4all-lora-quantized.bin',
}

module.exports = config;